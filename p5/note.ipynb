{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估指标\n",
    "### 选择合适的指标\n",
    "在构建机器学习模型时，我们首先要选择性能指标，然后测试模型的表现如何。相关的指标有多个，具体取决于我们要尝试解决的问题。\n",
    "\n",
    "在可以选择性能指标之前，首先务必要认识到，机器学习研究的是如何学习根据数据进行预测。对于本课程和后续的“监督式机器学习”课程，我们将重点关注那些创建分类或创建预测回归类型的已标记数据。\n",
    "\n",
    "此外，在测试模型时，也务必要将数据集分解为训练数据和测试数据。如果不区分训练数据集和测试数据集，则在评估模型时会遇到问题，因为它已经看到了所有数据。我们需要的是独立的数据集，以确认模型可以很好地泛化，而不只是泛化到训练样本。在下一课中，我们将探讨模型误差的一些常见来源，并介绍如何正确分解本课程的“数据建模和验证”部分中的数据集。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类和回归\n",
    "分类涉及到根据未见过的样本进行预测，并确定新实例属于哪个类别。例如，可以根据蓝色或红色或者方形或圆形来组织对象，以便在看到新对象时根据其特征来组织对象。\n",
    "\n",
    "在回归中，我们想根据连续数据来进行预测。例如，我们有包含不同人员的身高、年龄和性别的列表，并想预测他们的体重。或者，像在本课程的最终项目中一样，我们可能有一些房屋数据，并想预测某所住宅的价值。\n",
    "\n",
    "手头的问题在很大程度上决定着我们如何评估模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类指标与回归指标\n",
    "在分类中，我们想了解模型隔多久正确或不正确地识别新样本一次。而在回归中，我们可能更关注模型的预测值与真正值之间差多少。\n",
    "\n",
    "在本节课的余下部分，我们会探讨几个性能指标。对于分类，我们会探讨准确率、精确率、召回率和 F 分数。对于回归，我们会探讨平均绝对误差和均方误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类指标\n",
    "对于分类，我们处理的是根据离散数据进行预测的模型。这就是说，此类模型确定新实例是否属于给定的一组类别。在这里，我们测量预测是否准确地将所讨论的实例进行分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 分数\n",
    "既然我们已讨论了精确率和召回率，接下来可能要考虑的另一个指标是 F1 分数。F1 分数会同时考虑精确率和召回率，以便计算新的分数。\n",
    "\n",
    "可将 F1 分数理解为精确率和召回率的加权平均值，其中 F1 分数的最佳值为 1、最差值为 0：\n",
    "\n",
    "F1 = 2 * (精确率 * 召回率) / (精确率 + 召回率)\n",
    "\n",
    "有关 F1 分数和如何在 sklearn 中使用它的更多信息，请查看此链接[此处](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归指标\n",
    "正如前面对问题的回归类型所做的介绍，我们处理的是根据连续数据进行预测的模型。在这里，我们更关注预测的接近程度。\n",
    "\n",
    "例如，对于身高和体重预测，我们不是很关心模型能否将某人的体重 100% 准确地预测到小于零点几磅，但可能很关心模型如何能始终进行接近的预测（可能与个人的真实体重相差 3-4 磅）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均绝对误差\n",
    "您可能已回想起，在统计学中可以使用绝对误差来测量误差，以找出预测值与真实值之间的差距。平均绝对误差的计算方法是，将各个样本的绝对误差汇总，然后根据数据点数量求出平均误差。通过将模型的所有绝对值加起来，可以避免因预测值比真实值过高或过低而抵销误差，并能获得用于评估模型的整体误差指标。\n",
    "\n",
    "有关平均绝对误差和如何在 sklearn 中使用它的更多信息，请查看此链接[此处](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均方误差\n",
    "均方误差是另一个经常用于测量模型性能的指标。与绝对误差相比，残差（预测值与真实值的差值）被求平方。\n",
    "\n",
    "对残差求平方的一些好处是，自动将所有误差转换为正数、注重较大的误差而不是较小的误差以及在微积分中是可微的（可让我们找到最小值和最大值）。\n",
    "\n",
    "有关均方误差和如何在 sklearn 中使用它的更多信息，请查看此链接[此处](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归分数函数\n",
    "除了误差指标之外，scikit-learn还包括了两个分数指标，范围通常从0到1，值0为坏，而值1为最好的表现，看起来和分类指标类似，都是数字越接近1.0分数就越好。\n",
    "\n",
    "其中之一是[R2分数](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)，用来计算真值预测的可决系数。在 scikit-learn 里，这也是回归学习器默认的分数方法。\n",
    "\n",
    "另一个是[可释方差分数](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)\n",
    "\n",
    "虽然眼下我们不会详细探讨这些指标，一个要记住的重点是，回归的默认指标是“分数越高越好”；即，越高的分数表明越好的表现。而当我们用到前面讲的误差指标时，我们要改变这个设定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 误差原因\n",
    "### 误差原因\n",
    "我们已讨论了一些用于测量模型性能的基本指标，现在来关注一下模型起初为何会出现误差。\n",
    "\n",
    "在模型预测中，模型可能出现的误差来自两个主要来源，即：因模型无法表示基本数据的复杂度而造成的偏差（bias），或者因模型对训练它所用的有限数据过度敏感而造成的方差（variance）。我们会对两者进行更详细的探讨。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偏差造成的误差 - 准确率和欠拟合\n",
    "如前所述，如果模型具有足够的数据，但因不够复杂而无法捕捉基本关系，则会出现偏差。这样一来，模型一直会系统地错误表示数据，从而导致准确率降低。这种现象叫做欠拟合（underfitting）。\n",
    "\n",
    "简单来说，如果模型不适当，就会出现偏差。举个例子：如果对象是按颜色和形状分类的，但模型只能按颜色来区分对象和将对象分类（模型过度简化），因而一直会错误地分类对象。\n",
    "\n",
    "或者，我们可能有本质上是多项式的连续数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据并不重要，因为模型根本无法表示其中的基本关系，我们需要更复杂的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方差造成的误差 - 精度和过拟合\n",
    "在训练模型时，通常使用来自较大训练集的有限数量样本。如果利用随机选择的数据子集反复训练模型，可以预料它的预测结果会因提供给它的具体样本而异。在这里，方差（variance）用来测量预测结果对于任何给定的测试样本会出现多大的变化。\n",
    "\n",
    "出现方差是正常的，但方差过高表明模型无法将其预测结果泛化到更多的数据。对训练集高度敏感也称为过拟合（overfitting），而且通常出现在模型过于复杂或我们没有足够的数据支持它时。\n",
    "\n",
    "通常，可以利用更多数据进行训练，以降低模型预测结果的方差并提高精度。如果没有更多的数据可以用于训练，还可以通过限制模型的复杂度来降低方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习曲线\n",
    "现在你理解了偏差和方差的概念，让我们学习一下如何辨别模型表现的好坏。sklearn中的学习曲线函数可以帮到我们。它可以让我们通过数据点来了解模型表现的好坏。\n",
    "\n",
    "可以先引入这个模块\n",
    "```python\n",
    "from sklearn.learning_curve import learning_curve # sklearn 0.17\n",
    "from sklearn.model_selection import learning_curve # sklearn 0.18\n",
    "```   \n",
    "文档中一个合理的实现是：\n",
    "```python\n",
    "learning_curve(\n",
    "    estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "```           \n",
    "这里estimator是我们正在用来预测的模型，例如它可以是`GaussianNB()`，`X`和`y`是特征和目标。`cv`是交叉验证生成器，例如`KFold()`，`n_jobs`是平行运算的参数，`train_sizes`是多少数量的训练数据用来生成曲线。\n",
    "\n",
    "在接下来的练习中，你将为我们设计好的一个模型定义学习曲线，来观察效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进模型的有效性\n",
    "我们可以看到，在给定一组固定数据时，模型不能过于简单或复杂。如果过于简单，模型无法了解数据并会错误地表示数据。但是，如果建立非常复杂的模型，则需要更多数据才能了解基本关系，否则十分常见的是，模型会推断出在数据中实际上并不存在的关系。\n",
    "\n",
    "关键在于，通过找出正确的模型复杂度来找到最大限度降低偏差和方差的最有效点。当然，数据越多，模型随着时间推移会变得越好。\n",
    "\n",
    "要详细了解偏差和方差，建议阅读 Scott Fortmann-Roe 撰写的[这篇文章](http://scott.fortmann-roe.com/docs/BiasVariance.html)。\n",
    "\n",
    "除了选定用来训练模型的数据子集外，您使用的哪些来自给定数据集的特征也会显著影响模型的偏差和方差？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习曲线与模型复杂度\n",
    "### 学习曲线\n",
    "让我们根据模型通过可视化图形从数据中学习的能力来探讨偏差与方差之间的关系。\n",
    "\n",
    "机器学习中的学习曲线是一种可视化图形，能根据一系列训练实例中的训练和测试数据比较模型的指标性能。\n",
    "\n",
    "在查看数据与误差之间的关系时，我们通常会看到，随着训练点数量的增加，误差会趋于下降。由于我们尝试构建从经验中学习的模型，因此这很有意义。\n",
    "\n",
    "我们将训练集和测试集分隔开，以便更好地了解能否将模型泛化到未见过的数据而不是拟合到刚见过的数据。\n",
    "\n",
    "在学习曲线中，当训练曲线和测试曲线均达到稳定阶段，并且两者之间的差距不再变化时，则可以确认模型已尽其所能地了解数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 偏差\n",
    "在训练误差和测试误差收敛并且相当高时，这实质上表示模型具有偏差。无论我们向其提供多少数据，模型都无法表示基本关系，因而出现系统性的高误差。\n",
    "\n",
    "#### 方差\n",
    "如果训练误差与测试误差之间的差距很大，这实质上表示模型具有高方差。与偏差模型不同的是，如果有更多可供学习的数据，或者能简化表示数据的最重要特征的模型，则通常可以改进具有方差的模型。\n",
    "\n",
    "#### 理想的学习曲线\n",
    "模型的最终目标是，误差小并能很好地泛化到未见过的数据（测试数据）。如果测试曲线和训练曲线均收敛，并且误差极低，就能看到这种模型。这种模型能根据未见过的数据非常准确地进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型复杂度\n",
    "与学习曲线图形不同，模型复杂度图形呈现的是模型复杂度如何改变训练曲线和测试曲线，而不是用以训练模型的数据点的数量。一般趋势是，随着模型增大，模型对固定的一组数据表现出更高的变化性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学习曲线与模型复杂度\n",
    "那么，学习曲线与模型复杂度之间有何关系？\n",
    "\n",
    "如果我们获取具有同一组固定数据的相同机器学习算法的学习曲线，但为越来越高的模型复杂度创建几个图形，则所有学习曲线图形均代表模型复杂度图形。这就是说，如果我们获取了每个模型复杂度的最终测试误差和训练误差，并依据模型复杂度将它们可视化，则我们能够看到随着模型的增大模型的表现有多好。\n",
    "\n",
    "#### 模型复杂度的实际使用\n",
    "既然知道了能通过分析模型复杂度图形来识别偏差和方差的问题，现在可利用一个可视化工具来帮助找出优化模型的方法。在下一部分中，我们会探讨 gridsearch 和如何微调模型以获得更好的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn中的GridSearchCV\n",
    "GridSearchCV 用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。它的好处是，只需增加几行代码，就能遍历多种组合。\n",
    "\n",
    "下面是来自 sklearn 文档 的一个示例：\n",
    "```python\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "```\n",
    "让我们逐行进行说明。\n",
    "```python\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "```\n",
    "\n",
    "参数字典以及他们可取的值。在这种情况下，他们在尝试找到`kernel`（可能的选择为 'linear' 和 'rbf' ）和 C（可能的选择为1和10）的最佳组合。\n",
    "\n",
    "这时，会自动生成一个不同（kernel、C）参数值组成的“网格”:\n",
    "\n",
    "| | |\n",
    "|----|----|\n",
    "|('rbf', 1)|('rbf', 10)\n",
    "|('linear', 1)|('linear', 10)\n",
    "\n",
    "\n",
    "各组合均用于训练 SVM，并使用交叉验证对表现进行评估。\n",
    "\n",
    "```python\n",
    "svr = svm.SVC()\n",
    "``` \n",
    "这与创建分类器有点类似，就如我们从第一节课一直在做的一样。但是请注意，“clf” 到下一行才会生成—这儿仅仅是在说采用哪种算法。另一种思考方法是，“分类器”在这种情况下不仅仅是一个算法，而是算法加参数值。请注意，这里不需对 kernel 或 C 做各种尝试；下一行才处理这个问题。\n",
    "\n",
    "```python\n",
    "clf = grid_search.GridSearchCV(svr, parameters) \n",
    "```\n",
    "这是第一个不可思议之处，分类器创建好了。 我们传达算法 (svr) 和参数 (parameters) 字典来尝试，它生成一个网格的参数组合进行尝试。\n",
    "```python\n",
    "clf.fit(iris.data, iris.target) \n",
    "```\n",
    "第二个不可思议之处。 拟合函数现在尝试了所有的参数组合，并返回一个合适的分类器，自动调整至最佳参数组合。现在您便可通过 clf.best_params_ 来获得参数值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
